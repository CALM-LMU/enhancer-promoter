{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = '.'\n",
    "\n",
    "\n",
    "detection_subdirectory = '.'\n",
    "# file_pattern = 'RadialSymmetry_results*_ch2*.csv'\n",
    "# file_pattern = 'fig2.csv'\n",
    "file_pattern = 'merge_fixed_filenames_goodonly.csv'\n",
    "\n",
    "# pixel_columns = [f\"{d}_2\" for d in \"zyx\"]\n",
    "pixel_columns = [f\"gauss_fit_mu_{d}\" for d in \"zyx\"]\n",
    "# pixel_columns = list('zyx')\n",
    "\n",
    "unit_columns = [f\"{d}_micron_shift_corrected\" for d in \"zyx\"]\n",
    "needs_pixel_size = False\n",
    "\n",
    "\n",
    "channel_column = 'channel'\n",
    "image_file_column = 'image_file'\n",
    "\n",
    "split_channel_filename = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "in_files = sorted((Path(in_path) / detection_subdirectory).glob(file_pattern))\n",
    "in_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from calmutils.misc.file_utils import get_common_subpath\n",
    "\n",
    "df = pd.concat([pd.read_csv(in_file) for in_file in in_files]).reset_index(drop=True)\n",
    "\n",
    "if split_channel_filename:\n",
    "    df[image_file_column] = df['img'].str.rsplit(\"_\", n=1, expand=True)[0]\n",
    "\n",
    "if needs_pixel_size:\n",
    "\n",
    "    from calmutils.imageio.nd2_helpers import get_pixel_size\n",
    "\n",
    "    dfis = []\n",
    "\n",
    "    for file, dfi in df.groupby(image_file_column):\n",
    "\n",
    "        # get file prefixes from remote paths in table and local mount (in_path)\n",
    "        # NOTE: we assume the paths share at least some common subpath\n",
    "        _, (prefix_remote, prefix_local), _ = get_common_subpath(file, in_path)\n",
    "\n",
    "        pixel_size = get_pixel_size(file.replace(prefix_remote, prefix_local, 1))\n",
    "        dfi[unit_columns] = dfi[pixel_columns] * pixel_size\n",
    "        dfis.append(dfi)\n",
    "\n",
    "    df = pd.concat(dfis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Check subpixel offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_subpixel = np.linalg.norm(df[pixel_columns].values - df[list('zyx')].values, axis=1)\n",
    "plt.hist(d_subpixel[d_subpixel<1], bins=100);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12,3))\n",
    "\n",
    "for dim, ax in zip(pixel_columns, axs):\n",
    "\n",
    "    a = df[dim] - np.round(df[dim])\n",
    "\n",
    "    # sns.histplot(df, x=a, ax=ax, hue=df[channel_column].astype(str), element='poly', stat='probability', common_norm=False)\n",
    "    sns.histplot(df, x=a, ax=ax, element='poly', stat='probability', common_norm=False)\n",
    "    # ax.hist(a, bins=20)\n",
    "    ax.set_title(dim)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.melt(id_vars='channel', value_vars=pixel_columns, var_name='dimension', value_name='location')\n",
    "df_plot['subpixel_offset'] = df_plot['location'] - df_plot['location'].round()\n",
    "df_plot\n",
    "\n",
    "grid = sns.FacetGrid(df_plot, col='dimension', hue='channel', height=3.5)\n",
    "grid.map(sns.histplot, 'subpixel_offset', element='step', stat='density', alpha=0.1, common_norm=False, bins=31)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.savefig(\"/home/david/Desktop/gs651_subpixel_offset_rsfish.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Distance between matched coordinates (remaining shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calmutils.localization.metrics import get_coord_distance_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "max_dist = 0.25\n",
    "\n",
    "ds_collected = []\n",
    "ks = []\n",
    "\n",
    "for k, dfi in df.groupby(image_file_column):\n",
    "\n",
    "    if len(dfi[channel_column].unique()) != 2:\n",
    "        continue\n",
    "\n",
    "    (_, dfi_ch1), (_, dfi_ch2) = dfi.groupby(channel_column)\n",
    "    coords_ch1 = dfi_ch1[unit_columns].values\n",
    "    coords_ch2 = dfi_ch2[unit_columns].values\n",
    "\n",
    "    d = get_coord_distance_matrix(coords_ch1, coords_ch2)\n",
    "    d[d>max_dist] = max_dist * 9000\n",
    "\n",
    "    # get optimal matching\n",
    "    ci, ri = linear_sum_assignment(d)\n",
    "\n",
    "    coords_ch1_matched = coords_ch1[ci[d[ci, ri] < max_dist]]\n",
    "    coords_ch2_matched = coords_ch2[ri[d[ci, ri] < max_dist]]\n",
    "\n",
    "    ds = coords_ch1_matched - coords_ch2_matched\n",
    "\n",
    "    ds_collected.append(ds)\n",
    "    ks.extend([k] * len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calmutils.descriptors import match_descriptors_kd\n",
    "from calmutils.descriptors import descriptor_local_qr\n",
    "\n",
    "descriptor_match_ratio = 2\n",
    "max_dist = 0.25\n",
    "\n",
    "ds_collected = []\n",
    "ks = []\n",
    "\n",
    "for k, dfi in df.groupby(image_file_column):\n",
    "\n",
    "    if len(dfi[channel_column].unique()) != 2:\n",
    "        continue\n",
    "\n",
    "    (_, dfi_ch1), (_, dfi_ch2) = dfi.groupby(channel_column)\n",
    "    coords_ch1 = dfi_ch1[unit_columns].values\n",
    "    coords_ch2 = dfi_ch2[unit_columns].values\n",
    "\n",
    "    desc_ch1, idx_ch1 = descriptor_local_qr(coords_ch1, redundancy=2, scale_invariant=True, progress_bar=False)\n",
    "    desc_ch2, idx_ch2 = descriptor_local_qr(coords_ch2, redundancy=2, scale_invariant=True, progress_bar=False)\n",
    "\n",
    "    matches = match_descriptors_kd(desc_ch1, desc_ch2, max_ratio=1/descriptor_match_ratio)\n",
    "\n",
    "    coords_ch1_matched = coords_ch1[idx_ch1[matches.T[0]]]\n",
    "    coords_ch2_matched = coords_ch2[idx_ch2[matches.T[1]]]\n",
    "\n",
    "    ds = coords_ch1_matched - coords_ch2_matched\n",
    "\n",
    "    # discard matches above max distance\n",
    "    sel = np.linalg.norm(ds, axis=1) <= max_dist\n",
    "    ds = ds[sel]\n",
    "    coords_ch1_matched = coords_ch1_matched[sel]\n",
    "    coords_ch2_matched = coords_ch2_matched[sel]\n",
    "\n",
    "    ds_collected.append(ds)\n",
    "    ks.extend([k] * len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.concat(ds_collected)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12,3))\n",
    "\n",
    "for i, (dim, ax) in enumerate(zip(unit_columns, axs)):\n",
    "\n",
    "    # sns.histplot(x=ds[:,i], ax=ax, element='poly', stat='density', common_norm=False, hue=ks, legend=False)\n",
    "    sns.histplot(x=ds[:,i], ax=ax, element='step', stat='density', common_norm=False, legend=False, alpha=0.1)\n",
    "    # ax.hist(a, bins=20)\n",
    "    ax.set_title(dim)\n",
    "    ax.set_xlim((-0.25, 0.25))\n",
    "\n",
    "sns.despine()\n",
    "print(f\"nr. of matched points: {len(ds)}\")\n",
    "print(f\"mean shift: {np.round(ds.mean(axis=0), 4)}\")\n",
    "print(f\"shift std. dev.: {np.round(ds.std(axis=0), 4)}\")\n",
    "\n",
    "print(f\"shift magnitude median: {np.round(np.median(np.linalg.norm(ds, axis=1)), 4)}\")\n",
    "\n",
    "np.round(np.cov(ds.T), 4)\n",
    "\n",
    "# plt.savefig(\"/home/david/Documents/PromoterEnhancer_Revision/PowerFigure/corrected_shifts.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaw (angle in xy)\n",
    "sns.histplot(x=np.atan2(*ds.T[[1,2]]), bins=30, element='step')\n",
    "\n",
    "# pitch (angle between z and xy projection (magnitude))\n",
    "# NOTE: result in -pi/2, pi/2, so for visualization purposes we multiply with 2\n",
    "sns.histplot(x=2 * np.atan2(ds[:,0], np.linalg.norm(ds[:, [1,2]], axis=1)), bins=30, element='step')\n",
    "\n",
    "plt.ylim((0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nd2\n",
    "import napari\n",
    "\n",
    "example_file = next(iter(dfi[\"image_file\"]))\n",
    "\n",
    "data = nd2.imread(example_file)\n",
    "data.shape\n",
    "\n",
    "viewer = napari.view_image(data[:,1], colormap='cyan', blending='additive')\n",
    "viewer.add_points(coords_ch1_matched, border_color='cyan', face_color='#0000', out_of_slice_display=True)\n",
    "\n",
    "viewer.add_image(data[:,2], colormap='magenta', blending='additive')\n",
    "viewer.add_points(coords_ch2_matched, border_color='magenta', face_color='#0000', out_of_slice_display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nd2\n",
    "\n",
    "example_file = \"/Volumes/agl_data/NanoFISH/Gabi/GS651_Nanog_2-color_2nM/raw/fov_001.nd2\"\n",
    "example_file = \"/Volumes/agl_data/NanoFISH/Gabi/GS651_Nanog_2-color_2nM/raw/Point0000_Point0000_Channel405 CSU-W1,561 CSU-W1,640 CSU-W1 _Seq0000.nd2\"\n",
    "\n",
    "with nd2.ND2File(example_file) as reader:\n",
    "    m = reader.experiment\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
