{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a3c953",
   "metadata": {},
   "source": [
    "# Estimation of Transformation between sets of coordinates\n",
    "\n",
    "## Input\n",
    "\n",
    "- two datasets with tables of coordinates (in physical units) to match\n",
    "\n",
    "## Output\n",
    "\n",
    "- two JSON files describing a **global transformation** from moving coordinates to target coordinates and **local transformations** for each image in the moving dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe950d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.transform import SimilarityTransform, EuclideanTransform\n",
    "from skimage.measure import ransac\n",
    "\n",
    "from calmutils.descriptors import descriptor_local_qr, match_descriptors_kd\n",
    "from utils.transform_helpers import affine_transform_nd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43ccf7",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40bb8dbc",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# base paths of target and moving dataset\n",
    "base_path_target = \"/home/stumberger/ep2024/RNA_DNA_FISH_spot_detection/example/DNAFISH/\"\n",
    "base_path_moving = \"/home/stumberger/ep2024/RNA_DNA_FISH_spot_detection/example/RNAFISH/\"\n",
    "\n",
    "# paths of coordinate tables relative to base paths\n",
    "# NOTE: can be paths to a single .csv file, but can also include wildcard (*) to combine multiple files\n",
    "coordinates_path_target = 'detections_beads/merge_global_coords.csv'\n",
    "coordinates_path_moving = 'detections_beads/merge_global_coords.csv'\n",
    "\n",
    "# subdirectory of moving dataset to save transform parameters to\n",
    "save_subdir = 'alignment_parameters'\n",
    "\n",
    "# name of world coordinates and \n",
    "coordinate_column_names = ['z_global_um', 'y_global_um', 'x_global_um']\n",
    "image_file_column_name = 'img'\n",
    "\n",
    "# in order of complexity:\n",
    "# euclidean: move & rotate, similarity: + scale, affine: + shear\n",
    "transform_type = 'similarity'\n",
    "\n",
    "# matching & RANSAC parameters\n",
    "# NOTE: for global, we do more rounds and use more lenient threshold\n",
    "descriptor_match_ratio = 2.0\n",
    "min_samples_ransac = 4\n",
    "residual_thresh_global = 10.0\n",
    "residual_thresh_local = 4.0\n",
    "ransac_rounds_global = 100_000\n",
    "ransac_rounds_local = 20_000\n",
    "\n",
    "# when doing local alignment, radius around center of moving image to consider (in um)\n",
    "match_radius = 25.0\n",
    "\n",
    "n_neighbors_descriptor = 4\n",
    "# descriptor redundancy\n",
    "# NOTE: will quickly become much slower when this value is increased\n",
    "descriptor_redundancy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8d544",
   "metadata": {},
   "source": [
    "## 1) Global Alignment\n",
    "\n",
    "First, we will load all fiducial coordinates for the moving and target dataset and try to find a geometric transform between them.\n",
    "\n",
    "**Make sure this works** (i.e. you have a reasonable amount of matches and inliers), as this is required for a local alignment (step 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930c514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1492/1492 [00:00<00:00, 5862.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1534/1534 [00:00<00:00, 6298.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# load tables\n",
    "df_target = pd.concat([pd.read_csv(f) for f in Path(base_path_target).glob(coordinates_path_target)])\n",
    "df_moving = pd.concat([pd.read_csv(f) for f in Path(base_path_moving).glob(coordinates_path_moving)])\n",
    "\n",
    "# get coordinates from tables\n",
    "coords_target = df_target[coordinate_column_names].values\n",
    "coords_moving = df_moving[coordinate_column_names].values\n",
    "\n",
    "# generate descriptors\n",
    "desc_target, idxs_target = descriptor_local_qr(coords_target, redundancy=descriptor_redundancy, n_neighbors=n_neighbors_descriptor, progress_bar=True)\n",
    "desc_moving, idxs_moving = descriptor_local_qr(coords_moving, redundancy=descriptor_redundancy, n_neighbors=n_neighbors_descriptor, progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d8f8a",
   "metadata": {},
   "source": [
    "### Estimate Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfedeef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 inliers of 60 matches (80.00 %).\n",
      "mean error of matched points: 0.60 µm.\n"
     ]
    }
   ],
   "source": [
    "# match descriptors and select matching coords\n",
    "matches_kd = match_descriptors_kd(desc_target, desc_moving, max_ratio=1/descriptor_match_ratio, cross_check=True)\n",
    "coords_target_match = coords_target[idxs_target[matches_kd.T[0]]]\n",
    "coords_moving_match = coords_moving[idxs_moving[matches_kd.T[1]]]\n",
    "\n",
    "# select transform based on name from parameters\n",
    "transform_type_class = {'euclidean': EuclideanTransform, 'similarity': SimilarityTransform, 'affine': affine_transform_nd(3)}[transform_type]\n",
    "\n",
    "# estimate transform with RANSAC\n",
    "transform_global, inliers_global = ransac((coords_moving_match, coords_target_match),\n",
    "                            transform_type_class, min_samples_ransac, residual_threshold=residual_thresh_global, max_trials=ransac_rounds_global,\n",
    "                            stop_probability=1)\n",
    "\n",
    "# get some metrics and print\n",
    "num_matches_global = len(coords_moving_match)\n",
    "num_inliers_global = inliers_global.sum()\n",
    "mean_error_global = np.linalg.norm(coords_target_match[inliers_global] - transform_global(coords_moving_match[inliers_global]), axis=1).mean()\n",
    "\n",
    "print(f'{num_inliers_global} inliers of {num_matches_global} matches ({100 * num_inliers_global / num_matches_global :.2f} %).')\n",
    "print(f'mean error of matched points: {mean_error_global :.2f} µm.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a30f89",
   "metadata": {},
   "source": [
    "### Save global results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096c0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_results = {\n",
    "    'transformations': [\n",
    "        {\n",
    "            'center_coords': list(map(float, coords_moving.mean(axis=0))),\n",
    "            'num_matches': num_matches_global,\n",
    "            'num_inliers': int(num_inliers_global),\n",
    "            'mean_error': float(mean_error_global),\n",
    "            'transform_type': transform_type,\n",
    "            'parameters': list(map(float, transform_global.params.flat))\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "if not (Path(base_path_moving) / save_subdir).exists():\n",
    "    (Path(base_path_moving) / save_subdir).mkdir()\n",
    "with open(Path(base_path_moving) / save_subdir / 'alignment_parameters_global.json', 'w') as fd:\n",
    "    json.dump(global_results, fd, indent=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
