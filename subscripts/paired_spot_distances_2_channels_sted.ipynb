{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11aa75e7-161d-4be9-8f2b-9fbbf9dc3995",
   "metadata": {},
   "source": [
    "# Match spots in STED detail images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484315c-b091-44af-898f-6f5afb8572d0",
   "metadata": {},
   "source": [
    "- Take dataframe of spots detected in STED detail images `spot_subfolder`.\n",
    "- Combine the spots from channel 0 (eg. promoter: 1 spot) and channel 1 (eg. enhancer, `n_enh` spots) in each image. Channel number is adjustable with `channels`.\n",
    "- Calculate distances between each pair.\n",
    "- Filter for images with exact number of enhnacers `n_enh` with max channel 0 - 1 distance `limit`.\n",
    "- Save result to `merge_distances.csv`.\n",
    "- Get list of \"good\" images (utilized in the `merge_distances.csv` dataframe).\n",
    "- Link detection projections of those images into `projections_subfolder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d28d73-a61e-4041-8bbb-0d1da9f900fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fbd1c-4303-4964-aa5c-dd47e6ad3fb7",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "in_path = \"/home/stumberger/ep2024/example2/\"\n",
    "spot_subfolder = \"detections/merge.csv\"\n",
    "out_subfolder = \"detections\"\n",
    "projections_subfolder = \"detections_good\"\n",
    "projections_vis_subfolder = \"detections/vis\"\n",
    "\n",
    "pixel_size = [0.045, 0.045, 0.06]  # pixel size x,y,z\n",
    "limit = 1.5 #max P-E distance to look at [um]\n",
    "n_enh = 3\n",
    "channels = [0,1] # fisrt is promoter channel, second is enhancer channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3ac4e-5f36-41f7-ae7b-5abaddbcd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the 2 spot channels\n",
    "def join_channels(data,pixel_size,limit,n_enh,channels):\n",
    "    \n",
    "    # Step 1: Group by 'img' and 'channel', then mutate 'n'\n",
    "    data['n'] = data.groupby(['img', 'channel'])['channel'].transform('size')\n",
    "    \n",
    "    # Step 2: Apply filter conditions\n",
    "    data1 = data[((data['channel'] == channels[0]) & (data['n'] == 1)) |\n",
    "                 ((data['channel'] == channels[1]) & (data['n'] > 0) & (data['n'] <= n_enh))]\n",
    "    \n",
    "    # Step 3: Select specific columns and mutate 'img'\n",
    "    data2 = data1[['img', 'channel', 'x', 'y', 'z', 'n', 'experiment.cell_type', 'preparation.date']].copy()\n",
    "    data2['img'] = data2['img'].str.replace(r\"_ch.*$\", \"\", regex=True)\n",
    "    \n",
    "    # Step 4: Create separate DataFrames for 'channel' == 0 and 'channel' == 1\n",
    "    df0 = data2[data2['channel'] == channels[0]]\n",
    "    df1 = data2[data2['channel'] == channels[1]]\n",
    "    \n",
    "    # Step 5: Perform a right join on 'img' and drop NAs\n",
    "    df = pd.merge(df0, df1, on='img', suffixes=('_0', '_1'), how='right').dropna()\n",
    "    \n",
    "    # Step 6: Calculate the 3D length ('len3d')\n",
    "    df['len3d'] = np.sqrt(\n",
    "        ((df['x_0'] - df['x_1']) * pixel_size[0])**2 +\n",
    "        ((df['y_0'] - df['y_1']) * pixel_size[1])**2 +\n",
    "        ((df['z_0'] - df['z_1']) * pixel_size[2])**2\n",
    "    )\n",
    "    \n",
    "    # Step 7: Filter by 'len3d' and group by 'img', then mutate 'n_1'\n",
    "    df = df[df['len3d'] <= limit]\n",
    "    df['n_1'] = df.groupby('img')['img'].transform('size')\n",
    "    df = df[df['n_1']==n_enh]\n",
    "    df = df[df['img'].str.contains('sted')]\n",
    "\n",
    "    return(df)\n",
    "\n",
    "# plot good detections\n",
    "def plot_good_imgs(csv_file,search_directory,output_directory):\n",
    "\n",
    "    good_imgs = []\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    # Set to hold core filenames\n",
    "    core_filenames = set()\n",
    "    \n",
    "    # Read the CSV file and extract core filenames\n",
    "    with open(csv_file) as f:\n",
    "        reader = csv.reader(f)\n",
    "        imgs = list(reader)\n",
    "    \n",
    "    imgs = [item for sublist in imgs for item in sublist]\n",
    "    \n",
    "    # get images which match the input list\n",
    "    for img in imgs:\n",
    "        name = os.path.basename(img)\n",
    "    \n",
    "        # get matching files\n",
    "        search_pattern = f\"*{name}_*\"\n",
    "        good_img = glob.glob(os.path.join(search_directory, search_pattern))\n",
    "        good_imgs.append(good_img)\n",
    "    \n",
    "    good_imgs1 = [item for sublist in good_imgs for item in sublist]\n",
    "    \n",
    "    # create symlink\n",
    "    for file_path in good_imgs1:\n",
    "        # Get the base name of the file \n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        # Construct the symlink path in the destination directory\n",
    "        symlink_path = os.path.join(output_directory, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Create the symlink\n",
    "            os.symlink(file_path, symlink_path)\n",
    "        except FileExistsError:\n",
    "            print(f'Symlink already exists for {file_path} -> {symlink_path}')\n",
    "        except Exception as e:\n",
    "            print(f'Error creating symlink for {file_path}: {e}')\n",
    "\n",
    "def create_folder(folder_path):\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27803e-a4d6-4d50-9b5b-d14946df70dd",
   "metadata": {},
   "source": [
    "# 1) Match spot pairs and filter for number of enhancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68a9df-c97e-40a2-b8d1-1dc3d8d92733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "data = pd.read_csv(f\"{in_path}/{spot_subfolder}\")\n",
    "distances = join_channels(data,pixel_size,limit,n_enh,channels)\n",
    "\n",
    "# save data \n",
    "distances.to_csv(f\"{in_path}/{out_subfolder}/merge_distances.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295c8e0-cec5-4946-aec9-a2ebd2e072d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(distances, x=\"len3d\",binwidth=0.05)\n",
    "\n",
    "print(\"Total of \", len(distances[['img']].drop_duplicates()), \"images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609070c4-298e-4d38-ac21-6a1baef4b91c",
   "metadata": {},
   "source": [
    "# 2) Get list of used images and create a seperate subfolder with their detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c031776-73ae-4172-a2a8-99405b043c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get good images and create folder with the detections\n",
    "good_imgs = distances[['img']].drop_duplicates()\n",
    "\n",
    "# save good imgs\n",
    "good_imgs_path = f\"{in_path}/{projections_subfolder}\"\n",
    "create_folder(good_imgs_path)\n",
    "good_imgs.to_csv(f\"{good_imgs_path}/good_imgs.csv\",index=False)\n",
    "\n",
    "plot_good_imgs(f\"{good_imgs_path}/good_imgs.csv\",\\\n",
    "               f\"{in_path}/{projections_vis_subfolder}\",\\\n",
    "               f\"{in_path}/{projections_subfolder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
