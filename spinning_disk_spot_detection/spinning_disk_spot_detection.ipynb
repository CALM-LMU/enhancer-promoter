{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf03d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import concurrent.futures\n",
    "import queue\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_notebook(parameters,notebook_to_run,parameters_common={}):\n",
    "    \n",
    "    # change to directory where the notebook is (resolve relative imports)\n",
    "    os.chdir(Path(notebook_to_run).absolute().parent)\n",
    "    \n",
    "    # run notebook\n",
    "    for parameters_spec in parameters_list:\n",
    "        parameters = {**parameters_common, **parameters_spec}\n",
    "\n",
    "        pm.execute_notebook(\n",
    "            notebook_to_run,\n",
    "            '/dev/null',\n",
    "            parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e85b4c7",
   "metadata": {},
   "source": [
    "# 0) Create projections\n",
    "**In:** folder with `.nd2` images\n",
    "\n",
    "**Out:** folder `projections` with maximum inensity projections `.png` images split by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1cffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_list = [\n",
    "    {\"in_path\": \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/raw\"}\n",
    "]\n",
    "notebook_to_run = \"/home/stumberger/ep2024/subscripts/nd2_make_projections.ipynb\"\n",
    "\n",
    "run_notebook(parameters_list,notebook_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f99ba48",
   "metadata": {},
   "source": [
    "# 1) Resave .nd2 to tif \n",
    "**In:** folder containing folder `raw` with `.nd2` images\n",
    "\n",
    "**Out:** folder `tif` with `.tif` images split by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb034710",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_list = [\n",
    "    {\"in_path\": \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/\"}\n",
    "]\n",
    "\n",
    "notebook_to_run = \"/home/stumberger/ep2024/subscripts/resave_nd2_as_tif.ipynb\"\n",
    "\n",
    "run_notebook(parameters_list,notebook_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e2f07",
   "metadata": {},
   "source": [
    "# 2) Spot detection\n",
    "\n",
    "**In:** \n",
    "- `tif_subfolder` containing single channel `tif` images\n",
    "- `out_subfolder` containing spot detection settings file `chX.txt` generated via RS-FISH Fiji plugin for each channel specified in `channels`\n",
    "- `acquisition_info.json` file with the sample metadata which you wish to be added to your spots\n",
    "\n",
    "**Out:**\n",
    "- folder containing a `csv` file for each provioded `tif`\n",
    "- `merge.csv` file combining spots and their metadata from all images in the batch\n",
    "- vis folder with detection visualization for all `tif`s as `png` (good for checking detection results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c9be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_list = [\n",
    "    {\"in_path\": \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/\"}\n",
    "]\n",
    "\n",
    "parameters_common = {\"channels\": [1,2],\n",
    "                    \"tif_subfolder\": \"tif\",\n",
    "                    \"out_subfolder\": \"detections\"}\n",
    "\n",
    "notebook_to_run = \"/home/stumberger/ep2024/subscripts/RS-FISH_spot_detection.ipynb\"\n",
    "\n",
    "run_notebook(parameters_list,notebook_to_run,parameters_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e12c8",
   "metadata": {},
   "source": [
    "# 3) Correct chromatic shift\n",
    "**In:** \n",
    "- `.json` chromatic shift estimation created with `chromatic_aberration_estimation_elastix.ipynb`\n",
    "- `.csv` table containing original coordinates and channels\n",
    "\n",
    "**Out:**\n",
    "- `.csv` tables with additional columns containing the corrected coordinates and the reference channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b45adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_list = [\n",
    "    {\"in_path\": \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/detections/\"}\n",
    "]\n",
    "\n",
    "parameters_common = {\"pixel_size\": [0.3,0.13,0.13],\n",
    "                     \"channel_aliases\" : {\n",
    "                        '405-CSU-W1': '405-CSU-W1',\n",
    "                        '488-CSU-W1': '488-CSU-W1',\n",
    "                        '561-CSU-W1': 1,\n",
    "                        '640-CSU-W1': 2},\n",
    "                     \"reference_channel\": '405-CSU-W1',\n",
    "                     \"transforms_path\": \"/home/stumberger/ep2024/example/chrom_shift_reference/nups_channel_registration.json\"\n",
    "                    }\n",
    "\n",
    "notebook_to_run = \"/home/stumberger/ep2024/subscripts/correct_chromatic_aberration_for_tables.ipynb\"\n",
    "\n",
    "run_notebook(parameters_list,notebook_to_run,parameters_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73016d3c",
   "metadata": {},
   "source": [
    "# 4) Segment cells\n",
    "**In:**\n",
    "- `in_path` folder containing `tif` folder with single channel `.tif` images\n",
    "- cellpose model\n",
    "\n",
    "**Out:**\n",
    "- `segmentation` folder with segmentation masks\n",
    "- `segmentation/vis` subfolder with segmentation visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import concurrent.futures\n",
    "import queue\n",
    "\n",
    "def execute_notebook(parameters):\n",
    "    pm.execute_notebook(\n",
    "        '/home/stumberger/ep2024/subscripts/cellpose_segmentation_3d.ipynb',\n",
    "        None,\n",
    "        parameters=parameters)\n",
    "\n",
    "def process_parameters(parameters_queue, parameters_common):\n",
    "    while not parameters_queue.empty():\n",
    "        parameters_spec = parameters_queue.get()\n",
    "        execute_notebook({**parameters_common, **parameters_spec})\n",
    "        parameters_queue.task_done()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parameters_common = {\n",
    "        \"model\": \"/home/stumberger/ep2024/example/segmentation_model/es_20231026\"}\n",
    "\n",
    "    parameters_list =     parameters_list = parameters_list = [\n",
    "    {\"in_path\": \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/\"}\n",
    "]\n",
    "\n",
    "    batch_size = 3  # Number of parallel tasks\n",
    "\n",
    "    parameters_queue = queue.Queue()\n",
    "    for parameters_spec in parameters_list:\n",
    "        parameters_queue.put(parameters_spec)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "        # Start the initial batch\n",
    "        initial_batch = [executor.submit(execute_notebook, {**parameters_common, **parameters_queue.get()}) for _ in range(batch_size)]\n",
    "        \n",
    "        # Continue processing new tasks as previous ones complete\n",
    "        while not parameters_queue.empty():\n",
    "            # Wait for any task in the initial batch to complete\n",
    "            concurrent.futures.wait(initial_batch, return_when=concurrent.futures.FIRST_COMPLETED)\n",
    "            \n",
    "            # Replace completed tasks with new tasks\n",
    "            completed = [task for task in initial_batch if task.done()]\n",
    "            for task in completed:\n",
    "                initial_batch.remove(task)\n",
    "                new_task = executor.submit(execute_notebook, {**parameters_common, **parameters_queue.get()})\n",
    "                initial_batch.append(new_task)\n",
    "\n",
    "        # Wait for all tasks to complete\n",
    "        concurrent.futures.wait(initial_batch)\n",
    "\n",
    "    parameters_queue.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68dcdf",
   "metadata": {},
   "source": [
    "# 4.1) Add segmentation info to spots\n",
    "**In:**\n",
    "- segmentation masks in either `npy` or `png` format (name should correspond to the name of the image in the spot file)\n",
    "- `.csv` file of spots in each of the 2 channels, containg following columns:\n",
    "    - *img* - image name\n",
    "    - *channel* channel number the spot belongs to  \n",
    "    - *x, y* and *z* coordiantes\n",
    "\n",
    "**Out:**\n",
    "- `.csv` file of spots with addtional columns:\n",
    "    - *cell* - cell number in that particular image (0 means outside of cell)\n",
    "    - *whole_cell* - marks `False` for all cells touching the image border\n",
    "- optionally removes spots outside of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_common = {\n",
    "    \"filter\": True, # remove spots outsde of cells?\n",
    "    \"mask_ending\": \"_seg\",\n",
    "    \"spot_file\": \"merge_shift-corrected.csv\"}\n",
    "\n",
    "parameters_list = [\n",
    "    {\"in_path\": \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/\"}\n",
    "]\n",
    "\n",
    "notebook_to_run = \"/home/stumberger/ep2024/subscripts/assign_spots_to_cell.ipynb\"\n",
    "\n",
    "run_notebook(parameters_list,notebook_to_run,parameters_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e828f2a9",
   "metadata": {},
   "source": [
    "# 4.2) Quality measure: calculate sensitivity\n",
    "**In:**\n",
    "- segmentation masks in either `npy` or `png` format (name should correspond to the name of the image in the spot file)\n",
    "- `.csv` file of spots containing:\n",
    "    - *img* - image name\n",
    "    - *channel* - channel number the spot belongs to  \n",
    "    - *x, y* and *z* coordiantes\n",
    "\n",
    "**Out:**\n",
    "- `spots_per_cell.csv` with information on how many spots each cell in an image and channel contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6088f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_common = {\"mask_ending\": \"_seg\",\n",
    "                    \"rel_spot_path\": \"/detections/merge_filtered.csv\"} #spot path relative to upper folder}\n",
    "\n",
    "parameters_list = [\n",
    "    {\"in_path\": \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/\"}\n",
    "]\n",
    "\n",
    "notebook_to_run = \"/home/stumberger/ep2024/subscripts/calculate_spots_per_cell.ipynb\"\n",
    "\n",
    "run_notebook(parameters_list,notebook_to_run,parameters_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5129fd7c",
   "metadata": {},
   "source": [
    "# 5) Calculate distances\n",
    "**In:** \n",
    "- `in_path` working folder\n",
    "- `rel_spot_path` subpath to the processed spot files, relative to `in_path`\n",
    "\n",
    "**Out:**\n",
    "- `distances.csv` file with distances between spots matched in 2 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_common = {\n",
    "    \"rel_spot_path\": \"/detections/merge_shift-corrected.csv\",\n",
    "        \"channels\": [1,2],\n",
    "        \"voxel_size\": [300, 150, 150]}\n",
    "\n",
    "parameters_list = [\n",
    "     {\"in_path\": \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/\"}\n",
    "]\n",
    "\n",
    "notebook_to_run = \"/home/stumberger/ep2024/subscripts/paired_spot_distances_2_channels.ipynb\"\n",
    "\n",
    "run_notebook(parameters_list,notebook_to_run,parameters_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ace597-dfcf-46ff-8b43-faaa4d779969",
   "metadata": {},
   "source": [
    "# 6) Join csvs (optional)\n",
    "**In:** Paths to multiples folders containing the `distances.csv` files you want to join\n",
    "\n",
    "**Out:** `all_distances_filtered_{time}.csv` file with all `.csv`s joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2f30b-fecf-4530-8dfe-2e17770d06a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/\"\n",
    "\n",
    "csv_files = [\n",
    "    \"/home/stumberger/ep2024/spinning_disk_spot_detection/example/\"\n",
    "    ]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Read and store each CSV file as a DataFrame\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(f\"{file}/distances.csv\")\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Join the DataFrames using Pandas (e.g., concatenate them vertically)\n",
    "joined_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the joined DataFrame to a new csvfile\n",
    "time =  datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "joined_dataframe.to_csv(f'{wd}/all_distances_filtered_{time}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
